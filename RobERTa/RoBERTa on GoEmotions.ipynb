{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa on GoEmotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from RoBERTa_model_class import RobertaClassificationModel\n",
    "from TextCleaner import TextCleaner\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"go_emotions\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Convert to pandas dataframes\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "dev_df = dataset[\"validation\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Convert to pandas dataframes\n",
    "train_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "dev_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "test_df.columns = [\"text\", \"emotions\", \"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner = TextCleaner(train_df, dev_df, test_df)\n",
    "cleaner.clean_all() # Apply all cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df['text'].tolist()\n",
    "dev_texts = dev_df['text'].tolist()\n",
    "test_texts = test_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43410"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have to cook myself</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>omg peyton is not good enough to help us in the playoffs dumbass broncos fans circa december 2015</td>\n",
       "      <td>[26]</td>\n",
       "      <td>edvnz26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes i heard about the f bombs that has to be why thanks for your reply until then hubby and i will anxiously wait üòù</td>\n",
       "      <td>[15]</td>\n",
       "      <td>ee3b6wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we need more boards and to create a bit more space for [NAME] then we will be good</td>\n",
       "      <td>[8, 20]</td>\n",
       "      <td>ef4qmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damn youtube and outrage drama is super lucrative for reddit</td>\n",
       "      <td>[0]</td>\n",
       "      <td>ed8wbdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it might be linked to the trust factor of your friend</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eczgv1o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "0                                                          my favourite food is anything i did not have to cook myself   \n",
       "1      now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead   \n",
       "2                                                                                       why the fuck is bayless isoing   \n",
       "3                                                                                          to make her feel threatened   \n",
       "4                                                                                               dirty southern wankers   \n",
       "5                    omg peyton is not good enough to help us in the playoffs dumbass broncos fans circa december 2015   \n",
       "6  yes i heard about the f bombs that has to be why thanks for your reply until then hubby and i will anxiously wait üòù   \n",
       "7                                   we need more boards and to create a bit more space for [NAME] then we will be good   \n",
       "8                                                         damn youtube and outrage drama is super lucrative for reddit   \n",
       "9                                                                it might be linked to the trust factor of your friend   \n",
       "\n",
       "  emotions      ids  \n",
       "0     [27]  eebbqej  \n",
       "1     [27]  ed00q6i  \n",
       "2      [2]  eezlygj  \n",
       "3     [14]  ed7ypvh  \n",
       "4      [3]  ed0bdzj  \n",
       "5     [26]  edvnz26  \n",
       "6     [15]  ee3b6wu  \n",
       "7  [8, 20]  ef4qmod  \n",
       "8      [0]  ed8wbdn  \n",
       "9     [27]  eczgv1o  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_df['emotions'].tolist()\n",
    "dev_labels = dev_df['emotions'].tolist()\n",
    "test_labels = test_df['emotions'].tolist()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels_bin = mlb.fit_transform(train_labels)\n",
    "dev_labels_bin = mlb.transform(dev_labels)\n",
    "test_labels_bin = mlb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_bin[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43410, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotion_mapping = {\n",
    "    '0' : 'admiration',\n",
    "    '1' : 'amusement',\n",
    "    '2' : 'anger',\n",
    "    '3' : 'annoyance',\n",
    "    '4' : 'approval',\n",
    "    '5' : 'caring',\n",
    "    '6' : 'confusion',\n",
    "    '7' : 'curiosity',\n",
    "    '8' : 'desire',\n",
    "    '9': 'disappointment',\n",
    "    '10': 'disapproval',\n",
    "    '11': 'disgust',\n",
    "    '12': 'embarrassment',\n",
    "    '13': 'excitement',\n",
    "    '14': 'fear',\n",
    "    '15': 'gratitude',\n",
    "    '16': 'grief',\n",
    "    '17': 'joy',\n",
    "    '18': 'love',\n",
    "    '19': 'nervousness',\n",
    "    '20': 'optimism',\n",
    "    '21': 'pride',\n",
    "    '22': 'realization',\n",
    "    '23': 'relief',\n",
    "    '24': 'remorse',\n",
    "    '25': 'sadness',\n",
    "    '26': 'surprise',\n",
    "    '27': 'neutral'\n",
    "}\n",
    "\n",
    "target_names = list(emotion_mapping.values())\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'roberta-base'\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 14:22:41.138678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 14:22:41.966506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14317 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "max_length = 128  # max length of input sequence\n",
    "\n",
    "train_encodings = roberta_tokenizer(train_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "dev_encodings = roberta_tokenizer(dev_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "test_encodings = roberta_tokenizer(test_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
       "array([    0,  8310,   114,    37,   473,   160,  1003,   961,    40,\n",
       "         206, 36279,   519,    10,  7923, 21927,   154,    19,    82,\n",
       "        1386,     9,   888,  1462,     2,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.input_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 14:22:45.221775: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "roberta_classifier = RobertaClassificationModel(checkpoint = model_checkpoint, max_length = 128)\n",
    "roberta_model = roberta_classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 128)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['attention_mask_layer[0][0]',   \n",
      " el)                            thPoolingAndCrossAt               'input_ids_layer[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=(                                               \n",
      "                                (None, 128, 768),                                                 \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)),                                               \n",
      "                                 attentions=((None,                                               \n",
      "                                 12, None, 128),                                                  \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28)),                                                             \n",
      "                                 cross_attentions=N                                               \n",
      "                                one)                                                              \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['tf_roberta_model[0][26]']      \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 28)           21532       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,667,164\n",
      "Trainable params: 124,667,164\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# confirm all layers are frozen\n",
    "roberta_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2714/2714 [==============================] - 230s 80ms/step - loss: 0.1088 - accuracy: 0.4840 - val_loss: 0.0944 - val_accuracy: 0.5223\n",
      "Epoch 2/4\n",
      "2714/2714 [==============================] - 219s 81ms/step - loss: 0.0869 - accuracy: 0.5654 - val_loss: 0.0887 - val_accuracy: 0.5492\n",
      "Epoch 3/4\n",
      "2714/2714 [==============================] - 229s 84ms/step - loss: 0.0791 - accuracy: 0.6004 - val_loss: 0.0870 - val_accuracy: 0.5590\n",
      "Epoch 4/4\n",
      "2714/2714 [==============================] - 217s 80ms/step - loss: 0.0722 - accuracy: 0.6347 - val_loss: 0.0883 - val_accuracy: 0.5551\n"
     ]
    }
   ],
   "source": [
    "roberta_model_history = roberta_model.fit(\n",
    "    [train_encodings.input_ids, train_encodings.attention_mask],\n",
    "    train_labels_bin,  # Using binarized labels\n",
    "    validation_data=(\n",
    "        [dev_encodings.input_ids,  dev_encodings.attention_mask],\n",
    "        dev_labels_bin  # Using binarized labels\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 8s 49ms/step - loss: 0.0863 - accuracy: 0.5629\n",
      "Test loss: 0.08629786223173141\n",
      "Test accuracy: 0.5629261136054993\n"
     ]
    }
   ],
   "source": [
    " # test the model on the test set and print the neccessary results\n",
    "score = roberta_model.evaluate([test_encodings.input_ids, test_encodings.attention_mask],\n",
    "                                                  test_labels_bin)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run predict for the first three elements in the test data set\n",
    "# predictions = roberta_model.predict([test_encodings.input_ids[:3], test_encodings.attention_mask[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 11s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "#run and capture all predictions from our test set using model.predict\n",
    "predictions_model1 = roberta_model.predict([test_encodings.input_ids, test_encodings.attention_mask])\n",
    "\n",
    "threshold = 0.3\n",
    "binary_predictions = (predictions_model1 > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.73      0.60      0.66       504\n",
      "     amusement       0.83      0.76      0.80       264\n",
      "         anger       0.69      0.24      0.36       198\n",
      "     annoyance       0.54      0.12      0.19       320\n",
      "      approval       0.74      0.15      0.25       351\n",
      "        caring       0.44      0.40      0.42       135\n",
      "     confusion       0.59      0.17      0.26       153\n",
      "     curiosity       0.48      0.43      0.45       284\n",
      "        desire       0.68      0.25      0.37        83\n",
      "disappointment       0.90      0.06      0.11       151\n",
      "   disapproval       0.62      0.19      0.29       267\n",
      "       disgust       0.85      0.23      0.36       123\n",
      " embarrassment       0.53      0.27      0.36        37\n",
      "    excitement       0.54      0.33      0.41       103\n",
      "          fear       0.76      0.54      0.63        78\n",
      "     gratitude       0.94      0.90      0.92       352\n",
      "         grief       0.00      0.00      0.00         6\n",
      "           joy       0.81      0.50      0.62       161\n",
      "          love       0.78      0.86      0.82       238\n",
      "   nervousness       0.43      0.13      0.20        23\n",
      "      optimism       0.70      0.38      0.49       186\n",
      "         pride       0.50      0.06      0.11        16\n",
      "   realization       0.54      0.13      0.21       145\n",
      "        relief       0.67      0.18      0.29        11\n",
      "       remorse       0.57      0.75      0.65        56\n",
      "       sadness       0.80      0.40      0.54       156\n",
      "      surprise       0.70      0.31      0.43       141\n",
      "       neutral       0.72      0.53      0.61      1787\n",
      "\n",
      "     micro avg       0.72      0.45      0.55      6329\n",
      "     macro avg       0.65      0.35      0.42      6329\n",
      "  weighted avg       0.71      0.45      0.52      6329\n",
      "   samples avg       0.50      0.47      0.48      6329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_bin, binary_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_labels = mlb.inverse_transform(binary_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: i am really sorry about your situation although i love the names sapphira cirilla and scarlett\n",
      "Actual Labels: ['sadness']\n",
      "Predicted Labels: ['love']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: it is wonderful because it is awful at not with\n",
      "Actual Labels: ['admiration']\n",
      "Predicted Labels: ['admiration']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: kings fan here good luck to you guys will be an interesting game to watch\n",
      "Actual Labels: ['excitement']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i did not know that thank you for teaching me something today\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: they got bored from haunting earth for thousands of years and ultimately moved on to the afterlife\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: thank you for asking questions and recognizing that there may be things that you do not know or understand about police tactics seriously thank you\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: you are welcome\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: 100 congrats on your job too\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i am sorry to hear that friend it is for the best most likely if she did not accept you for who you are\n",
      "Actual Labels: ['remorse']\n",
      "Predicted Labels: ['remorse']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: girlfriend weak as well that jump was pathetic\n",
      "Actual Labels: ['sadness']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: [NAME] has towed the line of the dark side he would not cross it by doing something like this\n",
      "Actual Labels: ['annoyance', 'disapproval']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: lol but i love your last name though xd\n",
      "Actual Labels: ['amusement', 'love']\n",
      "Predicted Labels: ['amusement', 'love']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: translation i wish i could afford it\n",
      "Actual Labels: ['desire']\n",
      "Predicted Labels: ['desire']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: it is great that you are a recovering addict that is cool have you ever tried dmt\n",
      "Actual Labels: ['admiration', 'curiosity']\n",
      "Predicted Labels: ['admiration', 'curiosity']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i have also heard that intriguing but also kind of scary\n",
      "Actual Labels: ['fear']\n",
      "Predicted Labels: ['fear']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i never wanted to punch osap harder after seeing that however not too hardly i cannot afford them taking everything away\n",
      "Actual Labels: ['disapproval']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: the thought of shooting anything at asylum seekers is appalling\n",
      "Actual Labels: ['fear']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: if the pain does not go away after 4 hours or so it is broke\n",
      "Actual Labels: ['sadness', 'neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: triggered welp guess it is time for me to reup lol\n",
      "Actual Labels: ['amusement']\n",
      "Predicted Labels: ['amusement']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i am autistic and i would appreciate if you remove that comment thanks\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i know you are joking but there are people here either stupid or desperate enough to believe and perpetuate such idiocy\n",
      "Actual Labels: ['amusement']\n",
      "Predicted Labels: ['annoyance']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: may regret asking but foid\n",
      "Actual Labels: ['remorse']\n",
      "Predicted Labels: ['remorse']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: after he left the bus the two harpies sat next to each other and discussed why they were unable to find a decent man\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: well there is cubs and otters too\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: watch vegan gains‚Äô video on that he had it when he was like 13 highly doubt he was juicing then\n",
      "Actual Labels: ['confusion', 'neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: again overall not just for me\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: this guy is a little turd but i love him so dearly i will pass on your kisses\n",
      "Actual Labels: ['admiration', 'love']\n",
      "Predicted Labels: ['love']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: possibly but not if it actually succedes\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: same here but it seems like that will make it more rewarding to actually build a base with gardens and stuff\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: what is your source for that just curious and yes i know it sounds like a tired contrarian statement\n",
      "Actual Labels: ['curiosity']\n",
      "Predicted Labels: ['curiosity']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: nj has zero of their own picks from the 2010 draft still in the org\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: what is that like like what is the thought process i do not know i know what is a weird questioni just cannot imagine\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['confusion']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: imagine having to pretend you did not edit your link the inferiority is dripping off you\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i am going to hold out hope for something minor even though it looked really bad just going to wait for the official news\n",
      "Actual Labels: ['optimism']\n",
      "Predicted Labels: ['optimism']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i mean yeah to be honest\n",
      "Actual Labels: ['approval', 'neutral']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: we need more content ok here is some ballerina shoes\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['desire']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i totally thought the same thing i was like oh honey nooooo\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['realization']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: hey that is a thought maybe we need [NAME] to be the celebrity vaccine endorsement\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i like to bring up the fact that all of these pyramid schemes have corporate offices that have the exact same structure they are railing against\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: in what universe lol the mr blue sky cover is one of the best on the album i am going to\n",
      "Actual Labels: ['admiration', 'amusement']\n",
      "Predicted Labels: ['admiration']\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    text_example = test_texts[i]\n",
    "    actual_emotion = test_df['emotions'].iloc[i]\n",
    "    \n",
    "    actual_labels = [emotion_mapping[str(label)] for label in actual_emotion]\n",
    "    predicted_labels = [emotion_mapping[str(label)] for label in test_pred_labels[i]]\n",
    "\n",
    "    print(f\"Text: {text_example}\")\n",
    "    print(f\"Actual Labels: {actual_labels}\")\n",
    "    print(f\"Predicted Labels: {predicted_labels}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
