{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dafa94b",
   "metadata": {},
   "source": [
    "## BERT Base-Cased Model on GoEmotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce44094a-54e4-42fd-ac50-c677b9abd2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f51207-bdd7-44f5-876e-e268644a596f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1861213a-ff50-4aaa-9f05-40017550dcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from bert_model_class import BertClassificationModel # Imports the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6844bf4e-ccdb-46a0-841e-7712f14d7033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10ae981b-d4cf-4fe6-a620-32881dd2f0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"go_emotions__train_clean.tsv\", delimiter='\\t')\n",
    "dev_df = pd.read_csv(\"go_emotions__val_clean.tsv\", delimiter='\\t')\n",
    "test_df = pd.read_csv(\"go_emotions_test_clean.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00e16507-82aa-4287-beee-12f9ae6cbc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to pandas dataframes\n",
    "train_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "dev_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "test_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "dev_df = dev_df.dropna(subset=['text'])\n",
    "test_df = test_df.dropna(subset=['text'])\n",
    "\n",
    "train_texts = train_df['text'].tolist()\n",
    "dev_texts = dev_df['text'].tolist()\n",
    "test_texts = test_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6868667e-4563-4336-9161-c2cec6993fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have t...</td>\n",
       "      <td>[28]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think...</td>\n",
       "      <td>[28]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>[3]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>[15]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>[4]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>omg peyton is not good enough to help us in th...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>edvnz26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes i heard about the f bombs that has to be w...</td>\n",
       "      <td>[16]</td>\n",
       "      <td>ee3b6wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we need more boards and to create a bit more s...</td>\n",
       "      <td>[9, 21]</td>\n",
       "      <td>ef4qmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damn youtube and outrage drama is super lucrat...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>ed8wbdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it might be linked to the trust factor of your...</td>\n",
       "      <td>[28]</td>\n",
       "      <td>eczgv1o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions      ids\n",
       "0  my favourite food is anything i did not have t...     [28]  eebbqej\n",
       "1  now if he does off himself everyone will think...     [28]  ed00q6i\n",
       "2                     why the fuck is bayless isoing      [3]  eezlygj\n",
       "3                        to make her feel threatened     [15]  ed7ypvh\n",
       "4                             dirty southern wankers      [4]  ed0bdzj\n",
       "5  omg peyton is not good enough to help us in th...     [27]  edvnz26\n",
       "6  yes i heard about the f bombs that has to be w...     [16]  ee3b6wu\n",
       "7  we need more boards and to create a bit more s...  [9, 21]  ef4qmod\n",
       "8  damn youtube and outrage drama is super lucrat...      [1]  ed8wbdn\n",
       "9  it might be linked to the trust factor of your...     [28]  eczgv1o"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37bbbe18-32a5-4873-a86f-054c317f8536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43406"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec4a797-7e5c-4069-b0ad-205a871ef4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit on the training data and transform\n",
    "train_labels_bin = mlb.fit_transform(train_df[\"emotions\"].tolist())\n",
    "dev_labels_bin = mlb.transform(dev_df[\"emotions\"].tolist())\n",
    "test_labels_bin = mlb.transform(test_df[\"emotions\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "450dc4bd-37a7-47b9-bfd5-1cfd430f3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9ce19e6-c5df-4701-8efa-949ad2e1a740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del dataset, train_df, dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6d97dec-62bf-43f9-849f-5e53b45ce08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotion_mapping = {\n",
    "    '1' : 'admiration',\n",
    "    '2' : 'amusement',\n",
    "    '3' : 'anger',\n",
    "    '4' : 'annoyance',\n",
    "    '5' : 'approval',\n",
    "    '6' : 'caring',\n",
    "    '7' : 'confusion',\n",
    "    '8' : 'curiosity',\n",
    "    '9' : 'desire',\n",
    "    '10': 'disappointment',\n",
    "    '11': 'disapproval',\n",
    "    '12': 'disgust', \n",
    "    '13': 'embarrassment',\n",
    "    '14': 'excitement',\n",
    "    '15': 'fear',\n",
    "    '16': 'gratitude',\n",
    "    '17': 'grief',\n",
    "    '18': 'joy',\n",
    "    '19': 'love',\n",
    "    '20': 'nervousness',\n",
    "    '21': 'optimism',\n",
    "    '22': 'pride',\n",
    "    '23': 'realization',\n",
    "    '24': 'relief',\n",
    "    '25': 'remorse',\n",
    "    '26': 'sadness',\n",
    "    '27': 'surprise',\n",
    "    '28': 'neutral'\n",
    "}\n",
    "\n",
    "target_names = list(emotion_mapping.values())\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d898239b-1388-4c70-a40f-7c612904c664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BERT Tokenization\n",
    "model_checkpoint = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "488519fa-2b5e-4e10-96e5-79ec1c01641d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my favourite food is anything i did not have to cook myself',\n",
       " 'now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead',\n",
       " 'why the fuck is bayless isoing',\n",
       " 'to make her feel threatened',\n",
       " 'dirty southern wankers']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a80b39d-bb24-4d6f-b58c-5d7ef7dab8c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 128  # max length of input sequence\n",
    "\n",
    "train_encodings = bert_tokenizer(train_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "dev_encodings = bert_tokenizer(dev_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "test_encodings = bert_tokenizer(test_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5be8619-d080-480b-81ec-e72928cb60c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
       "array([  101,  1208,  1191,  1119,  1674,  1228,  1471,  2490,  1209,\n",
       "        1341,  1119,  1116,  1515,   170,  4046, 13084,  1158,  1114,\n",
       "        1234,  1939,  1104,  2140,  2044,   102,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.input_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7164c7f8-c9b3-4892-9d3c-f65e2561ce96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:49:54.225491: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 84.95MiB (rounded to 89075712)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-07 13:49:54.225536: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-07 13:49:54.225547: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 13, Chunks in use: 11. 3.2KiB allocated for chunks. 2.8KiB in use in bin. 60B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225553: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225559: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 3.0KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225564: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 9.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225570: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 4, Chunks in use: 3. 23.5KiB allocated for chunks. 17.5KiB in use in bin. 15.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225575: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 11.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225579: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 21.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225583: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225587: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225591: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225595: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225599: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225604: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.50MiB allocated for chunks. 1.50MiB in use in bin. 1.50MiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225609: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 1. 7.46MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225613: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225617: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225621: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225625: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225631: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 3. 353.09MiB allocated for chunks. 277.15MiB in use in bin. 254.85MiB client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225637: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.225642: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:49:54.226419: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 84.95MiB was 64.00MiB, Chunk State: \n",
      "2023-11-07 13:49:54.226530: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 75.94MiB | Requested Size: 8B | in_use: 0 | bin_num: 18, prev:   Size: 2.25MiB | Requested Size: 2.25MiB | in_use: 1 | bin_num: -1, next:   Size: 84.95MiB | Requested Size: 84.95MiB | in_use: 1 | bin_num: -1\n",
      "2023-11-07 13:49:54.226537: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 379715584\n",
      "2023-11-07 13:49:54.226568: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000000 of size 256 next 1\n",
      "2023-11-07 13:49:54.226573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000100 of size 1280 next 2\n",
      "2023-11-07 13:49:54.226580: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000600 of size 256 next 3\n",
      "2023-11-07 13:49:54.226584: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000700 of size 256 next 4\n",
      "2023-11-07 13:49:54.226587: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000800 of size 3072 next 31\n",
      "2023-11-07 13:49:54.226591: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690001400 of size 3072 next 25\n",
      "2023-11-07 13:49:54.226594: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690002000 of size 6144 next 26\n",
      "2023-11-07 13:49:54.226597: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690003800 of size 6144 next 11\n",
      "2023-11-07 13:49:54.226600: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690005000 of size 3072 next 6\n",
      "2023-11-07 13:49:54.226604: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690005c00 of size 21504 next 28\n",
      "2023-11-07 13:49:54.226607: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269000b000 of size 6144 next 30\n",
      "2023-11-07 13:49:54.226611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269000c800 of size 3108864 next 14\n",
      "2023-11-07 13:49:54.226614: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690303800 of size 1572864 next 7\n",
      "2023-11-07 13:49:54.226618: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690483800 of size 2359296 next 16\n",
      "2023-11-07 13:49:54.226621: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f26906c3800 of size 2359296 next 29\n",
      "2023-11-07 13:49:54.226625: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690903800 of size 79626240 next 23\n",
      "2023-11-07 13:49:54.226628: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f26954f3800 of size 89075712 next 27\n",
      "2023-11-07 13:49:54.226632: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269a9e6800 of size 89101056 next 12\n",
      "2023-11-07 13:49:54.226635: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fedfb00 of size 256 next 22\n",
      "2023-11-07 13:49:54.226639: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fedfc00 of size 5632 next 15\n",
      "2023-11-07 13:49:54.226643: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee1200 of size 256 next 18\n",
      "2023-11-07 13:49:54.226646: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee1300 of size 12032 next 17\n",
      "2023-11-07 13:49:54.226649: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4200 of size 256 next 19\n",
      "2023-11-07 13:49:54.226653: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4300 of size 256 next 13\n",
      "2023-11-07 13:49:54.226656: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4400 of size 256 next 5\n",
      "2023-11-07 13:49:54.226659: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4500 of size 256 next 10\n",
      "2023-11-07 13:49:54.226662: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4600 of size 256 next 8\n",
      "2023-11-07 13:49:54.226666: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4700 of size 256 next 9\n",
      "2023-11-07 13:49:54.226669: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4800 of size 1792 next 20\n",
      "2023-11-07 13:49:54.226672: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4f00 of size 256 next 21\n",
      "2023-11-07 13:49:54.226675: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee5000 of size 256 next 24\n",
      "2023-11-07 13:49:54.226679: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee5100 of size 112439040 next 18446744073709551615\n",
      "2023-11-07 13:49:54.226683: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-11-07 13:49:54.226688: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 11 Chunks of size 256 totalling 2.8KiB\n",
      "2023-11-07 13:49:54.226693: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-07 13:49:54.226697: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-11-07 13:49:54.226700: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2023-11-07 13:49:54.226704: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 6144 totalling 12.0KiB\n",
      "2023-11-07 13:49:54.226709: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1572864 totalling 1.50MiB\n",
      "2023-11-07 13:49:54.226715: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2359296 totalling 2.25MiB\n",
      "2023-11-07 13:49:54.226720: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 89075712 totalling 84.95MiB\n",
      "2023-11-07 13:49:54.226724: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 89101056 totalling 84.97MiB\n",
      "2023-11-07 13:49:54.226728: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 112439040 totalling 107.23MiB\n",
      "2023-11-07 13:49:54.226732: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 280.93MiB\n",
      "2023-11-07 13:49:54.226736: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 379715584 memory_limit_: 379715584 available bytes: 0 curr_region_allocation_bytes_: 759431168\n",
      "2023-11-07 13:49:54.226745: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       379715584\n",
      "InUse:                       294576128\n",
      "MaxInUse:                    294576128\n",
      "NumAllocs:                          94\n",
      "MaxAllocSize:                112439040\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-07 13:49:54.226752: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***____________________***********************************************************************xxxxxx\n",
      "2023-11-07 13:49:54.228097: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received by layer \"bert\" (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#let's get a fresh instance of the bert_model -- good practice\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:2912\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2910\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2912\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:1138\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Set the serving spec quickly to ensure that Keras doesn't use the specific dummy input shapes as the spec\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# Setting it in build() allows users to override the shape when loading a non-pretrained model from config\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_save_spec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature)\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:1088\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:780\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 780\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:161\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape: tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    162\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    164\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    169\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    171\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    172\u001b[0m         )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received by layer \"bert\" (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "#let's get a fresh instance of the bert_model -- good practice\n",
    "model_checkpoint = 'bert-base-cased'\n",
    "bert_model = TFBertModel.from_pretrained(model_checkpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ea2b8-2acd-40f7-8aef-7a1f6e51fa42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def bert_base_classification_model(checkpoint = model_checkpoint,\n",
    "#                                   learning_rate=0.00005,\n",
    "#                                   dropout = 0.1,\n",
    "#                                   num_classes = 28):\n",
    "#     \"\"\"\n",
    "#     Trains and evaluates a BERT-base model for emotion classification using the Pooler Output for classification purposes\n",
    "\n",
    "#     Parameters:\n",
    "#         - train_data : ?\n",
    "#         - dev_data : ?\n",
    "\n",
    "#     Returns:\n",
    "#         - model (TFBertForSequenceClassification): The trained BERT model.\n",
    "#     \"\"\"\n",
    "\n",
    "#     input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "#     token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "#     attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "#     bert = TFBertModel.from_pretrained(checkpoint)\n",
    "#     bert.trainable = True # makes sure all layers are trainable\n",
    "\n",
    "#     bert_inputs = {'input_ids': input_ids,\n",
    "#                    'token_type_ids': token_type_ids,\n",
    "#                    'attention_mask': attention_mask}\n",
    "\n",
    "#     bert_out = bert(bert_inputs)\n",
    "\n",
    "#     pooler_token = bert_out[1]\n",
    "\n",
    "#     hidden = tf.keras.layers.Dropout(dropout)(pooler_token)\n",
    "\n",
    "#     classification = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='classification_layer')(hidden)\n",
    "\n",
    "#     classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs = [classification])\n",
    "\n",
    "#     classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#                                  loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "\n",
    "#     return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f21fe2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:50:46.629300: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 84.95MiB (rounded to 89075712)requested by op TruncatedNormal\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-07 13:50:46.629339: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-07 13:50:46.629348: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 13, Chunks in use: 11. 3.2KiB allocated for chunks. 2.8KiB in use in bin. 60B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629353: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629359: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 3.0KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629364: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 9.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629369: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 4, Chunks in use: 3. 23.5KiB allocated for chunks. 17.5KiB in use in bin. 15.0KiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629373: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 11.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629377: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 21.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629380: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629384: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629387: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629391: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629394: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629399: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.50MiB allocated for chunks. 1.50MiB in use in bin. 1.50MiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629403: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 1. 7.46MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629406: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629410: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629413: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629417: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629422: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 3. 353.09MiB allocated for chunks. 277.15MiB in use in bin. 254.85MiB client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629425: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629436: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 13:50:46.629441: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 84.95MiB was 64.00MiB, Chunk State: \n",
      "2023-11-07 13:50:46.629458: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 75.94MiB | Requested Size: 8B | in_use: 0 | bin_num: 18, prev:   Size: 2.25MiB | Requested Size: 2.25MiB | in_use: 1 | bin_num: -1, next:   Size: 84.95MiB | Requested Size: 84.95MiB | in_use: 1 | bin_num: -1\n",
      "2023-11-07 13:50:46.629461: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 379715584\n",
      "2023-11-07 13:50:46.629469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000000 of size 256 next 1\n",
      "2023-11-07 13:50:46.629473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000100 of size 1280 next 2\n",
      "2023-11-07 13:50:46.629476: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000600 of size 256 next 3\n",
      "2023-11-07 13:50:46.629479: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000700 of size 256 next 4\n",
      "2023-11-07 13:50:46.629482: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690000800 of size 3072 next 31\n",
      "2023-11-07 13:50:46.629485: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690001400 of size 3072 next 25\n",
      "2023-11-07 13:50:46.629488: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690002000 of size 6144 next 26\n",
      "2023-11-07 13:50:46.629491: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690003800 of size 6144 next 11\n",
      "2023-11-07 13:50:46.629494: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690005000 of size 3072 next 6\n",
      "2023-11-07 13:50:46.629496: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690005c00 of size 21504 next 28\n",
      "2023-11-07 13:50:46.629499: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269000b000 of size 6144 next 30\n",
      "2023-11-07 13:50:46.629502: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269000c800 of size 3108864 next 14\n",
      "2023-11-07 13:50:46.629505: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f2690303800 of size 1572864 next 7\n",
      "2023-11-07 13:50:46.629508: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690483800 of size 2359296 next 16\n",
      "2023-11-07 13:50:46.629511: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f26906c3800 of size 2359296 next 29\n",
      "2023-11-07 13:50:46.629514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f2690903800 of size 79626240 next 23\n",
      "2023-11-07 13:50:46.629517: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f26954f3800 of size 89075712 next 27\n",
      "2023-11-07 13:50:46.629520: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269a9e6800 of size 89101056 next 12\n",
      "2023-11-07 13:50:46.629525: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fedfb00 of size 256 next 22\n",
      "2023-11-07 13:50:46.629528: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fedfc00 of size 5632 next 15\n",
      "2023-11-07 13:50:46.629531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee1200 of size 256 next 18\n",
      "2023-11-07 13:50:46.629534: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee1300 of size 12032 next 17\n",
      "2023-11-07 13:50:46.629537: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4200 of size 256 next 19\n",
      "2023-11-07 13:50:46.629540: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4300 of size 256 next 13\n",
      "2023-11-07 13:50:46.629542: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4400 of size 256 next 5\n",
      "2023-11-07 13:50:46.629546: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4500 of size 256 next 10\n",
      "2023-11-07 13:50:46.629549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4600 of size 256 next 8\n",
      "2023-11-07 13:50:46.629552: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4700 of size 256 next 9\n",
      "2023-11-07 13:50:46.629555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f269fee4800 of size 1792 next 20\n",
      "2023-11-07 13:50:46.629558: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee4f00 of size 256 next 21\n",
      "2023-11-07 13:50:46.629560: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee5000 of size 256 next 24\n",
      "2023-11-07 13:50:46.629564: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f269fee5100 of size 112439040 next 18446744073709551615\n",
      "2023-11-07 13:50:46.629567: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-11-07 13:50:46.629571: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 11 Chunks of size 256 totalling 2.8KiB\n",
      "2023-11-07 13:50:46.629575: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-07 13:50:46.629579: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-11-07 13:50:46.629582: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2023-11-07 13:50:46.629585: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 6144 totalling 12.0KiB\n",
      "2023-11-07 13:50:46.629588: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1572864 totalling 1.50MiB\n",
      "2023-11-07 13:50:46.629592: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2359296 totalling 2.25MiB\n",
      "2023-11-07 13:50:46.629595: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 89075712 totalling 84.95MiB\n",
      "2023-11-07 13:50:46.629598: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 89101056 totalling 84.97MiB\n",
      "2023-11-07 13:50:46.629602: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 112439040 totalling 107.23MiB\n",
      "2023-11-07 13:50:46.629605: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 280.93MiB\n",
      "2023-11-07 13:50:46.629608: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 379715584 memory_limit_: 379715584 available bytes: 0 curr_region_allocation_bytes_: 759431168\n",
      "2023-11-07 13:50:46.629617: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       379715584\n",
      "InUse:                       294576128\n",
      "MaxInUse:                    294576384\n",
      "NumAllocs:                          95\n",
      "MaxAllocSize:                112439040\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-07 13:50:46.629624: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***____________________***********************************************************************xxxxxx\n",
      "2023-11-07 13:50:46.630152: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[28996,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n\nOOM when allocating tensor with shape[28996,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]\n\nCall arguments received by layer \"bert\" (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mBertClassificationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m bert_classifier\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m/global/u1/h/heavenk/other/bert_model_class.py:12\u001b[0m, in \u001b[0;36mBertClassificationModel.__init__\u001b[0;34m(self, checkpoint, max_length, learning_rate, dropout, num_classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m dropout\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m num_classes\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/u1/h/heavenk/other/bert_model_class.py:19\u001b[0m, in \u001b[0;36mBertClassificationModel.build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids_layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask_layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m bert \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m bert\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m bert_inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: input_ids,\n\u001b[1;32m     23\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: token_type_ids,\n\u001b[1;32m     24\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: attention_mask}\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:2912\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2910\u001b[0m         model\u001b[38;5;241m.\u001b[39mbuild()  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2912\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:1138\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Set the serving spec quickly to ensure that Keras doesn't use the specific dummy input shapes as the spec\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# Setting it in build() allows users to override the shape when loading a non-pretrained model from config\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_save_spec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature)\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:1088\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    425\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:780\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 780\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m~/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py:161\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape: tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    162\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    164\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    169\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    171\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    172\u001b[0m         )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n\nOOM when allocating tensor with shape[28996,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]\n\nCall arguments received by layer \"bert\" (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "bert_classifier = BertClassificationModel(checkpoint = model_checkpoint, max_length = 128)\n",
    "model = bert_classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02d4e129-1fef-40b0-a1be-1f77f5fd4d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# bert_classification_model = bert_base_classification_model(checkpoint=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2483dd7-f8ab-4ea0-9fd5-34dfb769bb53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 100)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 100)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
      "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
      "                                n_state=(None, 100,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 768)          0           ['tf_bert_model_1[0][1]']        \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 28)           21532       ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,331,804\n",
      "Trainable params: 108,331,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# confirm all layers are frozen\n",
    "bert_classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f12e7341-ad8b-4800-9b9b-1c57f7e80916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(bert_classification_model, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "493713a9-b630-4e1b-bf56-53b302f5a49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2714/2714 [==============================] - 203s 71ms/step - loss: 0.1026 - accuracy: 0.5138 - val_loss: 0.0885 - val_accuracy: 0.5461\n",
      "Epoch 2/4\n",
      "2714/2714 [==============================] - 191s 70ms/step - loss: 0.0799 - accuracy: 0.5969 - val_loss: 0.0860 - val_accuracy: 0.5673\n",
      "Epoch 3/4\n",
      "2714/2714 [==============================] - 191s 70ms/step - loss: 0.0649 - accuracy: 0.6715 - val_loss: 0.0900 - val_accuracy: 0.5569\n",
      "Epoch 4/4\n",
      "2714/2714 [==============================] - 191s 70ms/step - loss: 0.0494 - accuracy: 0.7502 - val_loss: 0.0983 - val_accuracy: 0.5404\n"
     ]
    }
   ],
   "source": [
    "bert_classification_model_history = bert_classification_model.fit(\n",
    "    [train_encodings.input_ids, train_encodings.token_type_ids, train_encodings.attention_mask],\n",
    "    train_labels_bin,  # Using binarized labels\n",
    "    validation_data=(\n",
    "        [dev_encodings.input_ids, dev_encodings.token_type_ids, dev_encodings.attention_mask],\n",
    "        dev_labels_bin  # Using binarized labels\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35ebeacd-d226-4d89-b36a-e0b93ac064e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 7s 39ms/step - loss: 0.0974 - accuracy: 0.5351\n",
      "Test loss: 0.09744096547365189\n",
      "Test accuracy: 0.5351022481918335\n"
     ]
    }
   ],
   "source": [
    " # test the model on the test set and print the neccessary results\n",
    "score = bert_classification_model.evaluate([test_encodings.input_ids, test_encodings.token_type_ids, test_encodings.attention_mask],\n",
    "                                                  test_labels_bin)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a37ff73-ccaf-4c1c-a8d6-daf4f245993e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# run predict for the first three elements in the test data set\n",
    "predictions = bert_classification_model.predict([test_encodings.input_ids[:3], test_encodings.token_type_ids[:3], test_encodings.attention_mask[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48014af7-fda0-411a-8e8d-89ca98dc6742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 7s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "#run and capture all predictions from our test set using model.predict\n",
    "predictions_model1 = bert_classification_model.predict([test_encodings.input_ids, test_encodings.token_type_ids, test_encodings.attention_mask])\n",
    "\n",
    "threshold = 0.3\n",
    "binary_predictions = (predictions_model1 > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07bd2c39-0480-4d25-987f-5fc87c1bb4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.63      0.72      0.67       504\n",
      "     amusement       0.78      0.80      0.79       264\n",
      "         anger       0.48      0.48      0.48       198\n",
      "     annoyance       0.35      0.30      0.33       320\n",
      "      approval       0.34      0.41      0.37       351\n",
      "        caring       0.39      0.32      0.35       135\n",
      "     confusion       0.50      0.33      0.40       153\n",
      "     curiosity       0.43      0.73      0.54       284\n",
      "        desire       0.50      0.45      0.47        83\n",
      "disappointment       0.26      0.29      0.28       151\n",
      "   disapproval       0.39      0.36      0.37       267\n",
      "       disgust       0.50      0.45      0.47       123\n",
      " embarrassment       0.62      0.43      0.51        37\n",
      "    excitement       0.34      0.48      0.39       103\n",
      "          fear       0.63      0.68      0.65        78\n",
      "     gratitude       0.93      0.90      0.92       352\n",
      "         grief       0.67      0.33      0.44         6\n",
      "           joy       0.50      0.65      0.56       161\n",
      "          love       0.76      0.82      0.79       238\n",
      "   nervousness       0.37      0.30      0.33        23\n",
      "      optimism       0.56      0.58      0.57       186\n",
      "         pride       0.67      0.38      0.48        16\n",
      "   realization       0.29      0.19      0.23       145\n",
      "        relief       0.24      0.36      0.29        11\n",
      "       remorse       0.57      0.95      0.71        56\n",
      "       sadness       0.50      0.56      0.53       156\n",
      "      surprise       0.53      0.52      0.52       141\n",
      "       neutral       0.64      0.67      0.65      1787\n",
      "\n",
      "     micro avg       0.56      0.59      0.57      6329\n",
      "     macro avg       0.51      0.52      0.50      6329\n",
      "  weighted avg       0.56      0.59      0.57      6329\n",
      "   samples avg       0.57      0.61      0.57      6329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_bin, binary_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classification_model.save('bert_base_on_GoEmotions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49106cce",
   "metadata": {},
   "source": [
    "## Table with Results from Experiments\n",
    "\n",
    "| Model Name   | Max length | Hidden Units | Dropout | Learning Rate | Batch Size | Num. Epochs | Evaluation Data | Accuracy | Macro F1 Score | Precision | Recall | Total Parameters |\n",
    "|--------------|------------|--------------|---------|---------------|------------|------------|-----------------|----------|----------------|-----------|--------|------------------|\n",
    "| BERT-base    | 128        | N/A          | 0.1     | 0.00005       | 16         | 4          | Test Data       | -        | 0.50           | 0.51      | 0.52   | 108,331,804      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279786cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertModel.call of <transformers.models.bert.modeling_tf_bert.TFBertModel object at 0x7f9b61b63750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertModel.call of <transformers.models.bert.modeling_tf_bert.TFBertModel object at 0x7f9b61b63750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x7f9b61b63950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x7f9b61b63950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x7f9b61b3f4d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x7f9b61b3f4d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x7f9b61b3fe50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x7f9b61b3fe50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x7f9b5f99c150>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x7f9b5f99c150>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x7f9b61b63210>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x7f9b61b63210>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x7f9b61b634d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x7f9b61b634d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertSelfOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfOutput object at 0x7f9b5f98c0d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfOutput object at 0x7f9b5f98c0d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertIntermediate.call of <transformers.models.bert.modeling_tf_bert.TFBertIntermediate object at 0x7f9b5f98cd90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertIntermediate.call of <transformers.models.bert.modeling_tf_bert.TFBertIntermediate object at 0x7f9b5f98cd90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertOutput object at 0x7f9b5f98e190>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertOutput.call of <transformers.models.bert.modeling_tf_bert.TFBertOutput object at 0x7f9b5f98e190>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x7f9b61b3ff90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x7f9b61b3ff90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from transformers import TFBertModel\n",
    "\n",
    "# load the model \n",
    "with custom_object_scope({'TFBertModel': TFBertModel}):\n",
    "    loaded_model = load_model(\"bert_base_on_GoEmotions.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "facbc1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f9b5f934790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab6ea2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 630s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the dev set \n",
    "dev_predictions = loaded_model.predict([dev_encodings['input_ids'], dev_encodings['attention_mask'], dev_encodings[\"token_type_ids\"]]) \n",
    "\n",
    "# Thresholding predictions to get binary values. using 0.3 as it was used in the original paper\n",
    "dev_pred_bin = (dev_predictions > 0.3).astype(int)\n",
    "\n",
    "# Decode binary predictions to get emotion labels\n",
    "dev_pred_labels = mlb.inverse_transform(dev_pred_bin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b3201b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Is this in New Orleans?? I really feel like this is New Orleans.\n",
      "Actual Labels: ['surprise']\n",
      "Predicted Labels: ['caring', 'confusion', 'surprise']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n",
      "Actual Labels: ['annoyance', 'surprise']\n",
      "Predicted Labels: ['surprise']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: I've never been this sad in my life!\n",
      "Actual Labels: ['remorse']\n",
      "Predicted Labels: ['remorse']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n",
      "Actual Labels: ['annoyance', 'surprise']\n",
      "Predicted Labels: ['surprise']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n",
      "Actual Labels: ['nervousness']\n",
      "Predicted Labels: ['surprise']\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first 5 examples\n",
    "for i in range(5):\n",
    "    text_example = dev_texts[i]\n",
    "    actual_emotion = dev_df['emotions'].iloc[i]\n",
    "    \n",
    "    actual_labels = [emotion_mapping[str(label)] for label in actual_emotion]\n",
    "    predicted_labels = [emotion_mapping[str(label)] for label in dev_pred_labels[i]]\n",
    "\n",
    "    print(f\"Text: {text_example}\")\n",
    "    print(f\"Actual Labels: {actual_labels}\")\n",
    "    print(f\"Predicted Labels: {predicted_labels}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12cecfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1818afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dont know if i display all the emotions at once, so for now lets create heatmap for only one.\n",
    "# anger\n",
    "label_idx = target_names.index('anger')\n",
    "\n",
    "# Extract binary vectors for the chosen label from the actual and predicted matrices\n",
    "actual_binary = dev_labels_bin[:, label_idx]\n",
    "predicted_binary = dev_pred_bin[:, label_idx]\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(actual_binary, predicted_binary)\n",
    "\n",
    "# plot plot \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Not anger', 'Anger'], yticklabels=['Not anger', 'Anger'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for \"Anger\" Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db377a",
   "metadata": {},
   "source": [
    "## Grouped Taxonomy of Emotions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fadfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "\"positive\": [\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\", \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"],\n",
    "\"negative\": [\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\", \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"ambiguous\": [\"realization\", \"surprise\", \"curiosity\", \"confusion\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6757a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_predictions(predictions, mapping):\n",
    "    grouped_preds = np.zeros((predictions.shape[0], len(mapping)))\n",
    "\n",
    "    # Iterate over the mapping to sum the probabilities\n",
    "    for i, group in enumerate(mapping):\n",
    "        for emotion in mapping[group]:\n",
    "            # Find the index of the emotion in the original taxonomy\n",
    "            idx = target_names.index(emotion)\n",
    "            grouped_preds[:, i] += predictions[:, idx]\n",
    "\n",
    "    # Choose the predicted class based on the max probability\n",
    "    predicted_classes = np.argmax(grouped_preds, axis=1)\n",
    "\n",
    "    return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ebbd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65eb3a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 597s 4s/step\n"
     ]
    }
   ],
   "source": [
    "dev_predictions = loaded_model.predict([dev_encodings.input_ids, dev_encodings.token_type_ids, dev_encodings.attention_mask])\n",
    "predicted_classes = group_predictions(dev_predictions, mapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f21ce825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_new_taxonomy_binary(original_binary_labels, mlb, mapping, emotion_mapping):\n",
    "    # Convert binary labels to emotion labels\n",
    "    original_labels = mlb.inverse_transform(original_binary_labels)\n",
    "    \n",
    "    # Convert emotion labels to new taxonomy\n",
    "    new_taxonomy_labels = []\n",
    "    for labels in original_labels:\n",
    "        new_labels = set()\n",
    "        for label in labels:\n",
    "            emotion_str = emotion_mapping.get(str(label))\n",
    "            if not emotion_str:  # If the emotion is not in the mapping, skip it\n",
    "                continue\n",
    "            for group, emotions in mapping.items():\n",
    "                if emotion_str in emotions:\n",
    "                    new_labels.add(group)\n",
    "        new_taxonomy_labels.append(list(new_labels))\n",
    "    \n",
    "    # Binarize for new taxonomy\n",
    "    new_mlb = MultiLabelBinarizer(classes=['positive', 'negative', 'ambiguous'])\n",
    "    new_binary_labels = new_mlb.fit_transform(new_taxonomy_labels)\n",
    "\n",
    "    return new_binary_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52b7b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels_grouped_bin = convert_to_new_taxonomy_binary(dev_labels_bin, mlb, mapping, emotion_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1193624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_labels_grouped_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d62d90b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Is this in New Orleans?? I really feel like this is New Orleans.\n",
      "True label(s): ambiguous\n",
      "Predicted label(s): ambiguous\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n",
      "True label(s): negative, ambiguous\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: I've never been this sad in my life!\n",
      "True label(s): negative\n",
      "Predicted label(s): negative\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n",
      "True label(s): negative, ambiguous\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n",
      "True label(s): negative\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n",
      "True label(s): negative\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: Wah Mum other people call me on my bullshit and I can't ban them , Go out side son.\n",
      "True label(s): positive\n",
      "Predicted label(s): negative\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: There it is!\n",
      "True label(s): ambiguous\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: At least now [NAME] has more time to gain his confidence\n",
      "True label(s): negative\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: Good. We don't want more thrash liberal offspring in this world.\n",
      "True label(s): negative\n",
      "Predicted label(s): positive\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert predicted classes to binary format\n",
    "predicted_binary = np.zeros((predicted_classes.shape[0], 3))\n",
    "for i, pred in enumerate(predicted_classes):\n",
    "    predicted_binary[i, pred] = 1\n",
    "\n",
    "# Convert the binary labels back to the string representation for the new taxonomy\n",
    "def binary_to_label(binary_labels, classes):\n",
    "    labels = []\n",
    "    for row in binary_labels:\n",
    "        current_labels = [classes[i] for i, val in enumerate(row) if val]\n",
    "        labels.append(current_labels)\n",
    "    return labels\n",
    "\n",
    "# Convert binary predictions to label names\n",
    "predicted_labels_list = binary_to_label(predicted_binary, ['positive', 'negative', 'ambiguous'])\n",
    "true_labels_list = binary_to_label(dev_labels_grouped_bin, ['positive', 'negative', 'ambiguous'])\n",
    "\n",
    "# Print first 10\n",
    "for i in range(10):\n",
    "    print(f\"Text: {dev_texts[i]}\")\n",
    "    print(f\"True label(s): {', '.join(true_labels_list[i])}\")\n",
    "    print(f\"Predicted label(s): {', '.join(predicted_labels_list[i])}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d62170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
