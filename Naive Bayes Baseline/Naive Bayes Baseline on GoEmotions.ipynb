{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hBHrtXk38qp"
      },
      "source": [
        "# Naive Bayes Baseline Creation for GoEmotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LdrEBGe93q9Z"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cRmhz6e43s1D"
      },
      "outputs": [],
      "source": [
        "# # Downloading the GoEmotions datasets directly \n",
        "# # For Colab\n",
        "# !wget https://raw.githubusercontent.com/google-research/google-research/master/goemotions/data/train.tsv\n",
        "# !wget https://raw.githubusercontent.com/google-research/google-research/master/goemotions/data/dev.tsv\n",
        "# !wget https://raw.githubusercontent.com/google-research/google-research/master/goemotions/data/test.tsv\n",
        "\n",
        "\n",
        "# For Laptop\n",
        "train_path = \"goemotions/train.tsv\"\n",
        "dev_path = \"goemotions/dev.tsv\"\n",
        "test_path = \"goemotions/test.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IRlJfDTe3tSA"
      },
      "outputs": [],
      "source": [
        "# For Colab\n",
        "# train_data = pd.read_csv('train.tsv', sep='\\t', header=None)\n",
        "# dev_data = pd.read_csv('dev.tsv', sep='\\t', header=None)\n",
        "# test_data = pd.read_csv('test.tsv', sep='\\t', header=None)\n",
        "\n",
        "# For Laptop\n",
        "train_data = pd.read_csv(train_path, sep='\\t', header=None)\n",
        "dev_data = pd.read_csv(dev_path, sep='\\t', header=None)\n",
        "\n",
        "train_data.columns = [\"text\", \"emotions\", \"ids\"]\n",
        "dev_data.columns = [\"text\", \"emotions\", \"ids\"]\n",
        "\n",
        "# Mapping of emotion IDs to their names\n",
        "emotion_mapping = {\n",
        "    '1' : 'admiration',\n",
        "    '2' : 'amusement',\n",
        "    '3' : 'anger',\n",
        "    '4' : 'annoyance',\n",
        "    '5' : 'approval',\n",
        "    '6' : 'caring',\n",
        "    '7' : 'confusion',\n",
        "    '8' : 'curiosity',\n",
        "    '9' : 'desire',\n",
        "    '10': 'disappointment',\n",
        "    '11': 'disapproval',\n",
        "    '12': 'disgust',\n",
        "    '13': 'embarrassment',\n",
        "    '14': 'excitement',\n",
        "    '15': 'fear',\n",
        "    '16': 'gratitude',\n",
        "    '17': 'grief',\n",
        "    '18': 'joy',\n",
        "    '19': 'love',\n",
        "    '20': 'nervousness',\n",
        "    '21': 'optimism',\n",
        "    '22': 'pride',\n",
        "    '23': 'realization',\n",
        "    '24': 'relief',\n",
        "    '25': 'remorse',\n",
        "    '26': 'sadness',\n",
        "    '27': 'surprise',\n",
        "    '28': 'neutral'\n",
        "}\n",
        "\n",
        "# function to replace a comma-separated list of emotion IDs with their names\n",
        "def map_emotion_ids_to_names(emotion_ids_str):\n",
        "    # Split the string by comma, replace each ID with its name, and then join them back\n",
        "    return ','.join([emotion_mapping.get(e_id, 'unknown') for e_id in emotion_ids_str.split(',')])\n",
        "\n",
        "train_data['emotions'] = train_data['emotions'].apply(map_emotion_ids_to_names)\n",
        "dev_data['emotions'] = dev_data['emotions'].apply(map_emotion_ids_to_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jexX5GH4F73"
      },
      "source": [
        "## Naive Bayes as Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hKKEn6Tl3vkN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the below code, I am only considering the first emotion as the only label. This is a multi-label dataset, which means that there can be more than one labels for a training example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHhl1ksX3wrT",
        "outputId": "fe7c5d16-6f38-4d73-ab12-fdc20c8c4310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3923700700331736\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "    admiration       0.74      0.25      0.37       297\n",
            "     amusement       0.80      0.08      0.15       192\n",
            "         anger       0.08      0.01      0.01       247\n",
            "     annoyance       0.48      0.05      0.08       355\n",
            "      approval       0.83      0.04      0.07       138\n",
            "        caring       0.75      0.02      0.04       136\n",
            "     confusion       0.43      0.03      0.05       205\n",
            "     curiosity       0.00      0.00      0.00        64\n",
            "        desire       0.50      0.01      0.02       129\n",
            "disappointment       0.00      0.00      0.00       246\n",
            "   disapproval       0.50      0.01      0.03        74\n",
            "       disgust       0.00      0.00      0.00        28\n",
            " embarrassment       1.00      0.04      0.07        78\n",
            "    excitement       0.00      0.00      0.00        74\n",
            "          fear       0.79      0.56      0.66       297\n",
            "     gratitude       0.00      0.00      0.00        10\n",
            "         grief       0.31      0.03      0.06       121\n",
            "           joy       0.79      0.12      0.21       181\n",
            "          love       0.00      0.00      0.00        11\n",
            "   nervousness       0.67      0.03      0.06       133\n",
            "      optimism       0.00      0.00      0.00         9\n",
            "         pride       0.00      0.00      0.00        86\n",
            "   realization       0.00      0.00      0.00         8\n",
            "        relief       1.00      0.04      0.08        47\n",
            "       remorse       0.00      0.00      0.00        85\n",
            "       sadness       0.00      0.00      0.00        95\n",
            "      surprise       0.35      0.96      0.51      1592\n",
            "       neutral       0.52      0.57      0.54       488\n",
            "\n",
            "      accuracy                           0.39      5426\n",
            "     macro avg       0.38      0.10      0.11      5426\n",
            "  weighted avg       0.44      0.39      0.28      5426\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Convert the texts into a matrix of tokens\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data['text'])\n",
        "X_dev = vectorizer.transform(dev_data['text'])\n",
        "\n",
        "#  only consider the first emotion for multi-labels\n",
        "y_train = train_data['emotions'].str.split(',').str[0]\n",
        "y_dev = dev_data['emotions'].str.split(',').str[0]\n",
        "\n",
        "# Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the dev set\n",
        "y_dev_pred = clf.predict(X_dev)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_dev, y_dev_pred))\n",
        "print(classification_report(y_dev, y_dev_pred, target_names=list(emotion_mapping.values())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below takes account the multi-label structure of the dataset and predicts the probability of each label.\n",
        "\n",
        "This is a more robust approch to build a baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqNItgzF31G3",
        "outputId": "0cf44936-fa4f-4992-a765-750820736b08"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Convert the text into a matrix of tokens\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data['text'])\n",
        "X_dev = vectorizer.transform(dev_data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<43410x26379 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 495838 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KtC8GqJC5e9W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:876: UserWarning: unknown class(es) ['unknown'] will be ignored\n",
            "  \"unknown class(es) {0} will be ignored\".format(sorted(unknown, key=str))\n"
          ]
        }
      ],
      "source": [
        "# Convert the comma-separated emotions into a binary matrix \n",
        "mlb = MultiLabelBinarizer(classes=list(emotion_mapping.values()))\n",
        "y_train_mlb = mlb.fit_transform(train_data['emotions'].str.split(','))\n",
        "y_dev_mlb = mlb.transform(dev_data['emotions'].str.split(','))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_mlb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "    admiration       0.69      0.09      0.16       303\n",
            "     amusement       0.25      0.01      0.02       195\n",
            "         anger       0.00      0.00      0.00       303\n",
            "     annoyance       0.38      0.02      0.04       397\n",
            "      approval       0.60      0.02      0.04       153\n",
            "        caring       0.29      0.01      0.03       152\n",
            "     confusion       0.38      0.02      0.04       248\n",
            "     curiosity       0.00      0.00      0.00        77\n",
            "        desire       0.25      0.01      0.01       163\n",
            "disappointment       0.10      0.00      0.01       292\n",
            "   disapproval       0.25      0.01      0.02        97\n",
            "       disgust       0.00      0.00      0.00        35\n",
            " embarrassment       0.33      0.01      0.02        96\n",
            "    excitement       0.33      0.01      0.02        90\n",
            "          fear       0.92      0.52      0.66       358\n",
            "     gratitude       0.00      0.00      0.00        13\n",
            "         grief       0.33      0.02      0.04       172\n",
            "           joy       0.65      0.09      0.15       252\n",
            "          love       0.00      0.00      0.00        21\n",
            "   nervousness       0.43      0.01      0.03       209\n",
            "      optimism       0.00      0.00      0.00        15\n",
            "         pride       0.00      0.00      0.00       127\n",
            "   realization       0.00      0.00      0.00        18\n",
            "        relief       0.33      0.01      0.03        68\n",
            "       remorse       0.00      0.00      0.00       143\n",
            "       sadness       0.00      0.00      0.00       129\n",
            "      surprise       0.58      0.30      0.40      1766\n",
            "       neutral       0.00      0.00      0.00         0\n",
            "\n",
            "     micro avg       0.60      0.14      0.22      5892\n",
            "     macro avg       0.25      0.04      0.06      5892\n",
            "  weighted avg       0.42      0.14      0.18      5892\n",
            "   samples avg       0.15      0.14      0.14      5892\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:80: UserWarning: Label not 27 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/heaven/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# OneVsRestClassifier with MultinomialNB as the estimator \n",
        "clf = OneVsRestClassifier(MultinomialNB())\n",
        "clf.fit(X_train, y_train_mlb)\n",
        "\n",
        "# Predict on the dev set\n",
        "y_dev_pred_mlb = clf.predict(X_dev)\n",
        "\n",
        "# Convert binary predictions back to labels\n",
        "y_dev_pred_labels = mlb.inverse_transform(y_dev_pred_mlb)\n",
        "\n",
        "# Evaluate \n",
        "print(classification_report(y_dev_mlb, y_dev_pred_mlb, target_names=mlb.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: Is this in New Orleans?? I really feel like this is New Orleans.\n",
            "Actual Labels: ['surprise']\n",
            "surprise: 0.11\n",
            "joy: 0.00\n",
            "annoyance: 0.00\n",
            "confusion: 0.00\n",
            "anger: 0.00\n",
            "\n",
            "==================================================\n",
            "\n",
            "Text: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n",
            "Actual Labels: ['annoyance', 'surprise']\n",
            "surprise: 0.85\n",
            "anger: 0.00\n",
            "annoyance: 0.00\n",
            "confusion: 0.00\n",
            "fear: 0.00\n",
            "\n",
            "==================================================\n",
            "\n",
            "Text: I've never been this sad in my life!\n",
            "Actual Labels: ['remorse']\n",
            "surprise: 0.02\n",
            "remorse: 0.02\n",
            "annoyance: 0.00\n",
            "desire: 0.00\n",
            "admiration: 0.00\n",
            "\n",
            "==================================================\n",
            "\n",
            "Text: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n",
            "Actual Labels: ['annoyance', 'surprise']\n",
            "surprise: 0.98\n",
            "annoyance: 0.00\n",
            "anger: 0.00\n",
            "disappointment: 0.00\n",
            "confusion: 0.00\n",
            "\n",
            "==================================================\n",
            "\n",
            "Text: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n",
            "Actual Labels: ['nervousness']\n",
            "surprise: 0.81\n",
            "annoyance: 0.00\n",
            "confusion: 0.00\n",
            "anger: 0.00\n",
            "nervousness: 0.00\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# I need to get the predict probabilities for the dev set first \n",
        "y_dev_pred_probs = clf.predict_proba(X_dev)\n",
        "\n",
        "# now to print  the first 5 dev examples and their top 5 predictions\n",
        "for i in range(5):\n",
        "    text_example = dev_data['text'].iloc[i]\n",
        "    actual_labels = dev_data['emotions'].iloc[i].split(',')\n",
        "    predicted_indices = y_dev_pred_probs[i].argsort()[-5:][::-1]  # added sort and get the top 5 labels for text\n",
        "    predicted_labels_with_probs = [(mlb.classes_[index], y_dev_pred_probs[i][index]) for index in predicted_indices]\n",
        "    \n",
        "    # Printing\n",
        "    print(f\"Text: {text_example}\")\n",
        "    print(f\"Actual Labels: {actual_labels}\")\n",
        "    for label, prob in predicted_labels_with_probs:\n",
        "        print(f\"{label}: {prob:.2f}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
