{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLNet on GoEmotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import XLNetModel, XLNetTokenizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from xlnet_model_class import XLNETClassificationModel\n",
    "import sentencepiece\n",
    "from TextCleaner import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"go_emotions\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Convert to pandas dataframes\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "dev_df = dataset[\"validation\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# set name of columns\n",
    "train_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "dev_df.columns = [\"text\", \"emotions\", \"ids\"]\n",
    "test_df.columns = [\"text\", \"emotions\", \"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner = TextCleaner(train_df, dev_df, test_df)\n",
    "cleaner.clean_all() # Apply all cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts = train_df['text'].tolist()\n",
    "dev_texts = dev_df['text'].tolist()\n",
    "test_texts = test_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43410"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i did not have to cook myself</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>omg peyton is not good enough to help us in the playoffs dumbass broncos fans circa december 2015</td>\n",
       "      <td>[26]</td>\n",
       "      <td>edvnz26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes i heard about the f bombs that has to be why thanks for your reply until then hubby and i will anxiously wait üòù</td>\n",
       "      <td>[15]</td>\n",
       "      <td>ee3b6wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we need more boards and to create a bit more space for [NAME] then we will be good</td>\n",
       "      <td>[8, 20]</td>\n",
       "      <td>ef4qmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damn youtube and outrage drama is super lucrative for reddit</td>\n",
       "      <td>[0]</td>\n",
       "      <td>ed8wbdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it might be linked to the trust factor of your friend</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eczgv1o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "0                                                          my favourite food is anything i did not have to cook myself   \n",
       "1      now if he does off himself everyone will think hes having a laugh screwing with people instead of actually dead   \n",
       "2                                                                                       why the fuck is bayless isoing   \n",
       "3                                                                                          to make her feel threatened   \n",
       "4                                                                                               dirty southern wankers   \n",
       "5                    omg peyton is not good enough to help us in the playoffs dumbass broncos fans circa december 2015   \n",
       "6  yes i heard about the f bombs that has to be why thanks for your reply until then hubby and i will anxiously wait üòù   \n",
       "7                                   we need more boards and to create a bit more space for [NAME] then we will be good   \n",
       "8                                                         damn youtube and outrage drama is super lucrative for reddit   \n",
       "9                                                                it might be linked to the trust factor of your friend   \n",
       "\n",
       "  emotions      ids  \n",
       "0     [27]  eebbqej  \n",
       "1     [27]  ed00q6i  \n",
       "2      [2]  eezlygj  \n",
       "3     [14]  ed7ypvh  \n",
       "4      [3]  ed0bdzj  \n",
       "5     [26]  edvnz26  \n",
       "6     [15]  ee3b6wu  \n",
       "7  [8, 20]  ef4qmod  \n",
       "8      [0]  ed8wbdn  \n",
       "9     [27]  eczgv1o  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_df['emotions'].tolist()\n",
    "dev_labels = dev_df['emotions'].tolist()\n",
    "test_labels = test_df['emotions'].tolist()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels_bin = mlb.fit_transform(train_labels)\n",
    "dev_labels_bin = mlb.transform(dev_labels)\n",
    "test_labels_bin = mlb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_bin[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43410, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotion_mapping = {\n",
    "    '0' : 'admiration',\n",
    "    '1' : 'amusement',\n",
    "    '2' : 'anger',\n",
    "    '3' : 'annoyance',\n",
    "    '4' : 'approval',\n",
    "    '5' : 'caring',\n",
    "    '6' : 'confusion',\n",
    "    '7' : 'curiosity',\n",
    "    '8' : 'desire',\n",
    "    '9': 'disappointment',\n",
    "    '10': 'disapproval',\n",
    "    '11': 'disgust',\n",
    "    '12': 'embarrassment',\n",
    "    '13': 'excitement',\n",
    "    '14': 'fear',\n",
    "    '15': 'gratitude',\n",
    "    '16': 'grief',\n",
    "    '17': 'joy',\n",
    "    '18': 'love',\n",
    "    '19': 'nervousness',\n",
    "    '20': 'optimism',\n",
    "    '21': 'pride',\n",
    "    '22': 'realization',\n",
    "    '23': 'relief',\n",
    "    '24': 'remorse',\n",
    "    '25': 'sadness',\n",
    "    '26': 'surprise',\n",
    "    '27': 'neutral'\n",
    "}\n",
    "\n",
    "target_names = list(emotion_mapping.values())\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFXLNetModel\n",
    "model_checkpoint = 'xlnet-base-cased' \n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 14:46:57.628973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 14:46:58.450538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14317 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "max_length = 128  # max length of input sequence\n",
    "\n",
    "train_encodings = xlnet_tokenizer(train_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "dev_encodings = xlnet_tokenizer(dev_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')\n",
    "test_encodings = xlnet_tokenizer(test_texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 14:47:01.707029: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'xlnet-base-cased' \n",
    "xlnet_classifier = XLNETClassificationModel(checkpoint = model_checkpoint, max_length = 128)\n",
    "xlnet_model = xlnet_classifier.model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 128)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 128)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['attention_mask_layer[0][0]',   \n",
      "                                last_hidden_state=(               'input_ids_layer[0][0]',        \n",
      "                                None, 128, 768),                  'token_type_ids_layer[0][0]']   \n",
      "                                 mems=((128, None,                                                \n",
      "                                768),                                                             \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768),                                                \n",
      "                                 (128, None, 768)),                                               \n",
      "                                 hidden_states=((No                                               \n",
      "                                ne, 128, 768),                                                    \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)),                                               \n",
      "                                 attentions=((None,                                               \n",
      "                                 12, 128, 128),                                                   \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8),                                                               \n",
      "                                 (None, 12, 128, 12                                               \n",
      "                                8)))                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tfxl_net_model[0][25]']        \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 28)           21532       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 116,739,868\n",
      "Trainable params: 116,739,868\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# confirm all layers are frozen\n",
    "xlnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2714/2714 [==============================] - 281s 99ms/step - loss: 0.1604 - accuracy: 0.2821 - val_loss: 0.1514 - val_accuracy: 0.2934\n",
      "Epoch 2/4\n",
      "2714/2714 [==============================] - 255s 94ms/step - loss: 0.1354 - accuracy: 0.3747 - val_loss: 0.0979 - val_accuracy: 0.5291\n",
      "Epoch 3/4\n",
      "2714/2714 [==============================] - 257s 95ms/step - loss: 0.0933 - accuracy: 0.5461 - val_loss: 0.0879 - val_accuracy: 0.5619\n",
      "Epoch 4/4\n",
      "2714/2714 [==============================] - 255s 94ms/step - loss: 0.0825 - accuracy: 0.5895 - val_loss: 0.0867 - val_accuracy: 0.5603\n"
     ]
    }
   ],
   "source": [
    "xlnet_model_history = xlnet_model.fit(\n",
    "    [train_encodings.input_ids,  train_encodings.token_type_ids, train_encodings.attention_mask],\n",
    "    train_labels_bin,  # Using binarized labels\n",
    "    validation_data=(\n",
    "        [dev_encodings.input_ids,  dev_encodings.token_type_ids, dev_encodings.attention_mask],\n",
    "        dev_labels_bin  # Using binarized labels\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 9s 56ms/step - loss: 0.0861 - accuracy: 0.5609\n",
      "Test loss: 0.0860939547419548\n",
      "Test accuracy: 0.5608991980552673\n"
     ]
    }
   ],
   "source": [
    " # test the model on the test set and print the neccessary results\n",
    "score = xlnet_model.evaluate([test_encodings.input_ids, test_encodings.token_type_ids, test_encodings.attention_mask],\n",
    "                                                  test_labels_bin)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# #run predict for the first three elements in the test data set\n",
    "# predictions = xlnet_model.predict([test_encodings.input_ids[:3], test_encodings.token_type_ids[:3], \n",
    "#                                    test_encodings.attention_mask[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 10s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "#run and capture all predictions from our test set using model.predict\n",
    "predictions_model1 = xlnet_model.predict([test_encodings.input_ids, test_encodings.token_type_ids,\n",
    "                                          test_encodings.attention_mask])\n",
    "\n",
    "threshold = 0.3\n",
    "binary_predictions = (predictions_model1 > threshold).astype(int)\n",
    "test_pred_labels = mlb.inverse_transform(binary_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.77      0.52      0.62       504\n",
      "     amusement       0.80      0.84      0.82       264\n",
      "         anger       0.67      0.33      0.44       198\n",
      "     annoyance       0.76      0.09      0.16       320\n",
      "      approval       0.67      0.18      0.29       351\n",
      "        caring       0.56      0.16      0.25       135\n",
      "     confusion       0.62      0.16      0.25       153\n",
      "     curiosity       0.68      0.05      0.09       284\n",
      "        desire       0.50      0.47      0.48        83\n",
      "disappointment       0.57      0.11      0.18       151\n",
      "   disapproval       0.45      0.25      0.32       267\n",
      "       disgust       0.92      0.19      0.31       123\n",
      " embarrassment       0.52      0.41      0.45        37\n",
      "    excitement       0.76      0.24      0.37       103\n",
      "          fear       0.79      0.49      0.60        78\n",
      "     gratitude       0.97      0.87      0.92       352\n",
      "         grief       0.00      0.00      0.00         6\n",
      "           joy       0.61      0.60      0.61       161\n",
      "          love       0.75      0.81      0.78       238\n",
      "   nervousness       0.00      0.00      0.00        23\n",
      "      optimism       0.55      0.60      0.57       186\n",
      "         pride       0.86      0.38      0.52        16\n",
      "   realization       0.89      0.06      0.10       145\n",
      "        relief       0.00      0.00      0.00        11\n",
      "       remorse       0.62      0.55      0.58        56\n",
      "       sadness       0.74      0.44      0.55       156\n",
      "      surprise       0.70      0.40      0.51       141\n",
      "       neutral       0.73      0.54      0.62      1787\n",
      "\n",
      "     micro avg       0.72      0.44      0.54      6329\n",
      "     macro avg       0.62      0.35      0.41      6329\n",
      "  weighted avg       0.71      0.44      0.50      6329\n",
      "   samples avg       0.49      0.46      0.47      6329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_bin, binary_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table with Results from Experiments\n",
    "\n",
    "| Model Name   | Max length | Hidden Units | Dropout | Learning Rate | Batch Size | Num. Epochs | Evaluation Data | Accuracy | Macro F1 Score | Precision | Recall | Total Parameters |\n",
    "|--------------|------------|--------------|---------|---------------|------------|------------|-----------------|----------|----------------|-----------|--------|------------------|\n",
    "| DistilBERT-cased    | 128        | N/A          | 0.1     | 0.00005       | 16         | 4          | Test Data       |        |     0.41      |    0.62   |  0.35   |    65,212,444     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: i am really sorry about your situation although i love the names sapphira cirilla and scarlett\n",
      "Actual Labels: ['sadness']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: it is wonderful because it is awful at not with\n",
      "Actual Labels: ['admiration']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: kings fan here good luck to you guys will be an interesting game to watch\n",
      "Actual Labels: ['excitement']\n",
      "Predicted Labels: ['optimism']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i did not know that thank you for teaching me something today\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: they got bored from haunting earth for thousands of years and ultimately moved on to the afterlife\n",
      "Actual Labels: ['neutral']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: thank you for asking questions and recognizing that there may be things that you do not know or understand about police tactics seriously thank you\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: you are welcome\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: 100 congrats on your job too\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i am sorry to hear that friend it is for the best most likely if she did not accept you for who you are\n",
      "Actual Labels: ['remorse']\n",
      "Predicted Labels: ['remorse']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: girlfriend weak as well that jump was pathetic\n",
      "Actual Labels: ['sadness']\n",
      "Predicted Labels: ['sadness']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: [NAME] has towed the line of the dark side he would not cross it by doing something like this\n",
      "Actual Labels: ['annoyance', 'disapproval']\n",
      "Predicted Labels: ['neutral']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: lol but i love your last name though xd\n",
      "Actual Labels: ['amusement', 'love']\n",
      "Predicted Labels: ['amusement', 'love']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: translation i wish i could afford it\n",
      "Actual Labels: ['desire']\n",
      "Predicted Labels: ['desire']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: it is great that you are a recovering addict that is cool have you ever tried dmt\n",
      "Actual Labels: ['admiration', 'curiosity']\n",
      "Predicted Labels: ['admiration']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i have also heard that intriguing but also kind of scary\n",
      "Actual Labels: ['fear']\n",
      "Predicted Labels: ['fear']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i never wanted to punch osap harder after seeing that however not too hardly i cannot afford them taking everything away\n",
      "Actual Labels: ['disapproval']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: the thought of shooting anything at asylum seekers is appalling\n",
      "Actual Labels: ['fear']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: if the pain does not go away after 4 hours or so it is broke\n",
      "Actual Labels: ['sadness', 'neutral']\n",
      "Predicted Labels: []\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: triggered welp guess it is time for me to reup lol\n",
      "Actual Labels: ['amusement']\n",
      "Predicted Labels: ['amusement']\n",
      "\n",
      "==================================================\n",
      "\n",
      "Text: i am autistic and i would appreciate if you remove that comment thanks\n",
      "Actual Labels: ['gratitude']\n",
      "Predicted Labels: ['gratitude']\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first 5 examples\n",
    "for i in range(20):\n",
    "    text_example = test_texts[i]\n",
    "    actual_emotion = test_df['emotions'].iloc[i]\n",
    "    \n",
    "    actual_labels = [emotion_mapping[str(label)] for label in actual_emotion]\n",
    "    predicted_labels = [emotion_mapping[str(label)] for label in test_pred_labels[i]]\n",
    "\n",
    "    print(f\"Text: {text_example}\")\n",
    "    print(f\"Actual Labels: {actual_labels}\")\n",
    "    print(f\"Predicted Labels: {predicted_labels}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
